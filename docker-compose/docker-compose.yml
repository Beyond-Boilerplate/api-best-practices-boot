version: '3.8'

services:
  # Resources Section (Redis)
  redis-master:
    image: redis:6.2
    container_name: redis-master
    command: ["redis-server", "/usr/local/etc/redis/redis.conf"]
    volumes:
      - ./redis/redis.conf:/usr/local/etc/redis/redis.conf
      - redis-master-data:/data
    ports:
      - "6379:6379"
    networks:
      - app-network
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 10s
      timeout: 5s
      retries: 5
    environment:
      - REDIS_PASSWORD=yourpassword

  redis-sentinel:
    image: redis:6.2
    container_name: redis-sentinel
    command: ["redis-sentinel", "/usr/local/etc/redis/sentinel.conf"]
    volumes:
      - ./redis/sentinel.conf:/usr/local/etc/redis/sentinel.conf
    ports:
      - "26379:26379"
    depends_on:
      redis-master:
        condition: service_healthy
    networks:
      - app-network

  # Application Section (Spring App and JMeter)
  spring-app:
    build:
      context: ../
      dockerfile: Dockerfile
    container_name: spring-app
    environment:
      - SPRING_DATA_REDIS_HOST=redis-master
      - SPRING_DATA_REDIS_PORT=6379
      - SPRING_DATA_REDIS_PASSWORD=yourpassword
    ports:
      - "8080:8080"
    depends_on:
      redis-master:
        condition: service_healthy  # Wait for Redis to be healthy
    networks:
      - app-network
    healthcheck:
      test: "curl --fail --silent http://localhost:8080/actuator/health/readiness | grep UP || exit 1"
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 30s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  jmeter:
    image: justb4/jmeter:5.5
    container_name: jmeter
    environment:
      - JVM_ARGS="-Xms1024m -Xmx2048m"
    volumes:
      - ./transaction_perf.jmx:/tests/api_performance_test.jmx
      - ./transactions.csv:/tests/transactions.csv
      - ./results:/tests/results
      - ./reports:/tests/reports
    command: >
      -n -t /tests/api_performance_test.jmx -l /tests/results/results.jtl -e -o /tests/reports
    depends_on:
      spring-app:
        condition: service_healthy  # Wait for Spring Boot to be healthy
    networks:
      - app-network
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # Metrics Section (Prometheus, Grafana, Loki, Promtail)
  read:
    image: grafana/loki:3.0.0
    command: "-config.file=/etc/loki/config.yaml -target=read"
    ports:
      - 3101:3100
      - 7946
      - 9095
    volumes:
      - ./loki/loki-config.yaml:/etc/loki/config.yaml
    depends_on:
      - minio
    healthcheck:
      test: [ "CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:3100/ready || exit 1" ]
      interval: 10s
      timeout: 5s
      retries: 5
    networks: &loki-dns
      app-network:
        aliases:
          - loki
    
  write:
    image: grafana/loki:3.0.0
    command: "-config.file=/etc/loki/config.yaml -target=write"
    ports:
      - 3102:3100
      - 7946
      - 9095
    volumes:
      - ./loki/loki-config.yaml:/etc/loki/config.yaml
    healthcheck:
      test: [ "CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:3100/ready || exit 1" ]
      interval: 10s
      timeout: 5s
      retries: 5
    depends_on:
      - minio
    networks:
      <<: *loki-dns

  alloy:
    image: grafana/alloy:v1.0.0
    volumes:
      - ./alloy/alloy-local-config.yaml:/etc/alloy/config.alloy:ro
      - /var/run/docker.sock:/var/run/docker.sock
    command: run --server.http.listen-addr=0.0.0.0:12345 --storage.path=/var/lib/alloy/data /etc/alloy/config.alloy
    ports:
      - 12345:12345
    depends_on:
      - gateway
    networks:
      - app-network

  minio:
    image: minio/minio:RELEASE.2024-05-27T19-17-46Z
    entrypoint:
      - sh
      - -euc
      - |
        mkdir -p /data/loki-data && \
        mkdir -p /data/loki-ruler && \
        minio server /data
    environment:
      - MINIO_ROOT_USER=loki
      - MINIO_ROOT_PASSWORD=supersecret
      - MINIO_PROMETHEUS_AUTH_TYPE=public
      - MINIO_UPDATE=off
    ports:
      - 9000
    volumes:
      - ./.data/minio:/data
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:9000/minio/health/live" ]
      interval: 15s
      timeout: 20s
      retries: 5
    networks:
      - app-network

  prometheus:
    image: prom/prometheus:v2.50.1
    container_name: prometheus
    ports:
      - "9090:9090"
    volumes:
      - ./prometheus/prometheus.yaml:/etc/prometheus/prometheus.yml
    networks:
      - app-network

  tempo:
    image: grafana/tempo:2.4.2
    container_name: tempo
    command: -config.file /etc/tempo-config.yml
    ports:
      - "3110:3100"
      - "4317:4317"
    volumes:
      - ./tempo/tempo.yaml:/etc/tempo-config.yml
    networks:
      - app-network

  grafana:
    image: grafana/grafana:11.0.0
    environment:
      - GF_PATHS_PROVISIONING=/etc/grafana/provisioning
      - GF_AUTH_ANONYMOUS_ENABLED=true
      - GF_AUTH_ANONYMOUS_ORG_ROLE=Admin
    depends_on:
      - gateway
    entrypoint:
      - sh
      - -euc
      - |
        /run.sh
    volumes:
      - ./grafana/datasource.yaml:/etc/grafana/provisioning/datasources/datasource.yml
    ports:
      - "3000:3000"
    healthcheck:
      test: [ "CMD-SHELL", "wget --no-verbose --tries=1 --spider http://localhost:3000/api/health || exit 1" ]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - app-network

  backend:
    image: grafana/loki:3.0.0
    volumes:
      - ./loki/loki-config.yaml:/etc/loki/config.yaml
    ports:
      - "3100"
      - "7946"
    command: "-config.file=/etc/loki/config.yaml -target=backend -legacy-read-mode=false"
    depends_on:
      - gateway
    networks:
      - app-network


  gateway:
    image: nginx:1.25.5
    depends_on:
      - read
      - write
    entrypoint:
      - sh
      - -euc
      - |
        cat <<EOF > /etc/nginx/nginx.conf
        user  nginx;
        worker_processes  5;  ## Default: 1
        
        events {
          worker_connections   1000;
        }
        
        http {
          resolver 127.0.0.11;
        
          server {
            listen             3100;
        
            location = / {
              return 200 'OK';
              auth_basic off;
            }
        
            location = /api/prom/push {
              proxy_pass       http://write:3100\$$request_uri;
            }
        
            location = /api/prom/tail {
              proxy_pass       http://read:3100\$$request_uri;
              proxy_set_header Upgrade \$$http_upgrade;
              proxy_set_header Connection "upgrade";
            }
        
            location ~ /api/prom/.* {
              proxy_pass       http://read:3100\$$request_uri;
            }
        
            location = /loki/api/v1/push {
              proxy_pass       http://write:3100\$$request_uri;
            }
        
            location = /loki/api/v1/tail {
              proxy_pass       http://read:3100\$$request_uri;
              proxy_set_header Upgrade \$$http_upgrade;
              proxy_set_header Connection "upgrade";
            }
        
            location ~ /loki/api/.* {
              proxy_pass       http://read:3100\$$request_uri;
            }
          }
        }
        EOF
        /docker-entrypoint.sh nginx -g "daemon off;"
    ports:
      - "3100:3100"
    healthcheck:
      test: [ "CMD", "service", "nginx", "status" ]
      interval: 10s
      timeout: 5s
      retries: 5
    networks:
      - app-network


networks:
  app-network:
    driver: bridge
  monitoring:
    driver: bridge

volumes:
  redis-master-data:
  redis-slave-data:
  grafana-storage:
